{"answers": ["C", "D", "C", "D", "A"], "options": [["It may constitute a challenge to computer progranmers.", "It accompanies all machinery involving high technology.", "It can be avoided if human values are translated into their language.", "It has become an inevitable peril as technology gets more sophisticated."], ["They are aggressive.", "They are outgoing.", "They are ignorant.", "They are ill-bred."], ["By interacting with humans in everyday life situations.", "By following the daily routines of civilized human beings.", "By picking up patterns from massive data on human behavior.", "By imitating the behavior of property brought-up human beings."], ["keep a distance from possible dangers.", "Stop to seek advice from a human being.", "Trigger its built-in alarm system at once.", "Do sufficient testing before taking action."], ["Determine what is moral and ethical.", "Design some large-scale experiments.", "Set rules for man-machine interaction.", "Develop a more sophisticated program."]], "questions": ["What does the author say about the threat of robots?", "What would we think of a person who invades our personal space according to the author?", "How do robots learn human values?", "What will a well-programmed robot do when facing an unusual situation?", "What is most difficult to do when we turn human values into a programmable code?"], "article": "As Artificial Intelligence(AI) becomes increasingly sophisticated, there are growing concerns that robots could become a threat. This danger can be avoided, according to computer science professor Stuart Russell, if we figure out how to turn human values into a programmable code.\nRussell argues that as robots take on more complicated tasks, it's necessary to translate our morals into AI language.\nFor example, if a robot does chores around the house, you wouldn't want it to put the pet cat in the oven to make dinner for the hungry children. \"You would want that robot preloaded with a good set of values,\" said Russell.\nSome robots are already programmed with basic human values. For example, mobile robots have been programmed to keep a comfortable distance from humans. Obviously there are cultural differences, but if you were talking to another person and they came up close in your personal space, you wouldn't think that's the kind of thing a properly brought-up person would do.\nIt will be possible to create more sophisticated moral machines, if only we can find a way to set out human values as clear rules.\nRobots could also learn values from drawing patterns from large sets of data on human behavior. They are dangerous only if programmers are careless.\nThe biggest concern with robots going against human values is that human beings fail to so sufficient testing and they've produced a system that will break some kind of taboo .\nOne simple check would be to program a robot to check the correct course of action with a human when presented with an unusual situation.\nIf the robot is unsure whether an animal is suitable for the microwave, it has the opportunity to stop, send out beeps , and ask for directions from a human. If we humans aren't quite sure about a decision, we go and ask somebody else.\nThe most difficult step in programming values will be deciding exactly what we believe in moral, and how to create a set of ethical rules. But if we come up with an answer, robots could be good for humanity.", "id": "high14711.txt"}